<!DOCTYPE html>

<html>
<head>
  <title>b(Ai)ttery ⤑ all</title>
  <meta http-equiv="content-type" content="text/html; charset=UTF-8">
  <meta name="viewport" content="width=device-width, target-densitydpi=160dpi, initial-scale=1.0, maximum-scale=1.0, user-scalable=0">
  <link rel="stylesheet" media="all" href="docco.css" />
</head>
<body>
  <div id="container">
    <div id="background"></div>
    
    <ul class="sections">
        
          <li id="title">
              <div class="annotation">
                  <h1>b(Ai)ttery ⤑ all</h1>
              </div>
          </li>
        
        
        
        <li id="section-1">
            <div class="annotation">
              
              <div class="sswrap ">
                <a class="ss" href="#section-1">&#x00a7;</a>
              </div>
              <p><span id="forkongithub"><a href="https://github.com/timm/shortr#shortrlua--less-but-better-xai-eyes">Fork me on GitHub</a></span>
<img align=left width=225   src="bat2.png"></p>
<p>LUA is a “batteries-not-included” language.
But LUA makes it easy to add in the  missing bits.
E.g. here are some “b(Ai)tteries” for XAI.</p>
<p>(c) 2022, Tim Menzies<br><a href="mailto:&#x74;&#x69;&#109;&#x6d;&#x40;&#x69;&#x65;&#x65;&#101;&#46;&#x6f;&#x72;&#x67;">&#x74;&#x69;&#109;&#x6d;&#x40;&#x69;&#x65;&#x65;&#101;&#46;&#x6f;&#x72;&#x67;</a></p>
<p><strong>config:</strong> <a href="all.html">all</a></p>
<p><strong>build:</strong> <a href="https://github.com/timm/shortr/blob/master/etc/src/Makefile">Makefile</a><br>(just used for the doco)</p>
<p><strong>demos:</strong> <a href="go.html">go</a></p>
<p><strong>apps:</strong> <a href="nb.html">nb</a></p>
<p><strong>functions:</strong> <a href="lib.html">lib</a></p>
<p><strong>klasses:</strong> <a href="bin.html">bin</a>
:: <a href="cols.html">cols</a>
:: <a href="num.html">num</a>
:: <a href="row.html">row</a>
:: <a href="rows.html">rows</a>
:: <a href="some.html">some</a>
:: <a href="sym.html">sym</a></p>
<p><a href="https://zenodo.org/badge/latestdoi/206205826"> <img  src="https://zenodo.org/badge/206205826.svg" alt="DOI"></a> 
<a href="https://opensource.org/licenses/BSD-2-Clause"><img  src="https://img.shields.io/badge/License-BSD%202--Clause-orange.svg"></a></p>
<h2 id="about-xai-and-baittery">About XAI and b(Ai)ttery</h2>
<p>Explainable AI (XAI) is a subset of AI that tries
to build models that people can read and understand and critique and easily change. B(Ai)ttery
is a small set of classes that implements a few interesting
XAI tools. </p>
<p>For the “big picture” on XAI, see the Vilone and Logno’ 2020 systematic review.</p>
<p>For a small set of really useful XAI tactics, see below.</p>
<h3 id="about-xai">About XAI</h3>
<p>For years
I used   XAI to <em>augment</em> other more opaque AI tools.
But that meant I was not explaining the real inference
process, just some frail copy of what was really going on.</p>
<p>Then I found that XAI can (sometimes) actually 
<em>replace</em> other AI tools since, at least in the domains
I’ve explored, XAI tools can make better conclusions, 
faster, and those conclusions are explicable to people.</p>
<p>(Not always of course. If you gave me 10,000 wavelets
from a signal processing package then of course I’d 
reach for a deep learner.
But if you wanted to <em>tune</em> that deep
learner, then I’d still use this code since it
just runs a few what-of queries on the
most important parts of the data.)</p>
<p>XAI should be designed with an understanding of human
cognitive processes. People are clever, as Davenport and Beck remind us,
they  have [fixed and limited attention spans
which they  hoard and use sparingly.
Herbert Simon say that humans  use heuristic “short cuts” that let 
them satisfy the demands of their work, just enough
before rushing off to their next
task.</p>
<p>Once such short-cut is the “cue”; i.e. a small range
of some variable that most effects the outcome. Feature
extraction and weighting  is the process of finding
those cues. This code can be summarized as “the hunt
for ‘cues’”. </p>
<p>Another short-cut is sampling; i.e. don’t look at 
everything, just a few things. There are many ways to
sample and this code exploits them all (random, 
reservoir, extreme).</p>
<h3 id="references">References</h3>
<ul>
<li>Thomas H. Davenport and John C. Beck. (2001). 
<a href="https://ubiquity.acm.org/article.cfm?id=376626">The Attention economy</a>. 
Ubiquity 2001, May (May 1 - May 31, 2001), </li>
<li>Gigerenzer, G. (2008). 
<a href="https://pure.mpg.de/rest/items/item_2100099/component/file_2100098/content">Why Heuristics Work</a>.
Perspectives on Psychological Science, 3(1), 20–29. </li>
<li>Vilone, Giulia &amp; Longo, Luca. (2020). 
<a href="https://arxiv.org/pdf/2006.00093.pdf">Explainable Artificial Intelligence: a Systematic Review</a></li>
<li>Simon, Herbert A. (1956). 
<a href="https://uk.sagepub.com/sites/default/files/upm-binaries/25239_Chater~Vol_1~Ch_03.pdf">Rational Choice and the Structure of the Environment</a>
Psychological Review. 63 (2): 129–138.</li>
</ul>

            </div>
            
            <div class="content"><div class='highlight'><pre><span class="hljs-keyword">local</span> all=<span class="hljs-built_in">require</span><span class="hljs-string">&quot;lib&quot;</span>
all.the = all.opts( <span class="hljs-string">[[
BAITTERY: semi-supervised multi-objective optimization XAI
(c) 2022 Tim Menzies &lt;timm@ieee.org&gt; BSD2 license
     
From N items, find and explain the best ones, using just log(N) evals.
PASS1 (guess): eval two distant items on multi-objective criteria.
      Prune everything nearest the worst one. Recurse on rest.  
PASS2 (guess again): do it again, using better items from first pass.  
PASS3 (explain): recursively discretize attributes on how well they
      distinguish the best and worst items (seen in second pass).
   
USAGE:
  lua go.lua [OPTIONS]
   
OPTIONS:
  -M  --Min    min size of space                    =  .5
  -b  --bins   max number of bins                   =  16
  -F  --Far    how far to look for remove points    =  .95
  -k  --k      Bayes hack: low attribute frequency  =  2
  -m  --m      Bayes hack: low class frequency      =  1
  -p  --p      distance coefficient (2=Euclidean)   =  2
  -s  --seed   random number seed                   =  10019
  -S  --Some   max number of nums to keep           =  256
  -w  --wait   wait this number before testing      =  10
   
OPTIONS (other):
  -f  --file   file           =  ../../data/auto93.csv
  -g  --go     start-up goal  =  nothing
  -h  --help   show help      =  false ]]</span>)
   
<span class="hljs-keyword">return</span> all</pre></div></div>
            
        </li>
        
        
        <li id="section-2">
            <div class="annotation">
              
              <div class="sswrap ">
                <a class="ss" href="#section-2">&#x00a7;</a>
              </div>
              <p>XX
This code contains 
B(Ai)TTERY (a set of AI-related classes) and 
 various AI tools, coded on top of B(Ai)TTERY. </p>
<p>One of the  idea here is that that there the thing we call “data 
mining” shares many of its internal data structures and algorithms
with the thing we call “optimization”. So once we build those
internal things, then building “data miners” or “optimizers”
is a  pretty trivial extension. </p>
<h3 id="apps">Apps</h3>
<p> Naive Bays Classifier</p>
<p>Trees (regression and decision)</p>
<p> Recursive random projections</p>
<p>SHORTR:
Semi-supervised multi-objective optimization XAI
(from N items, find and explain the best ones, using just log(N) evals).
PASS1 (guess): eval two distant items on multi-objective criteria.
       Prune everything nearest the worst one. Recurse on rest.
PASS2 (guess again): do it again, using better items from first pass.
PASS3 (explain): recursively discretize attributes on how well they
      distinguish the best and worst items (seen in second pass).</p>
<h3 id="coding-conventions">Coding conventions</h3>
<p>Before reading this, it might  be best to<br>review these <a href="https://github.com/timm/shortr/blob/master/CONTRIBUTE.md">local coding conventions</a>.</p>
<h2 id="why-this-code">Why this code?</h2>
<p> This code is an experiment in “less-is-more”. Death to mash-ups and their associated 
 problems with technical debt and security problems that leak in from all 
 the parts used in the assembly.</p>
<p><b>Tony Hoare:</b><br>
<em>“Inside every large program is a small program struggling to get out.”</em><p>
<b>Alan Perlis:</b><br><em>“Simplicity does not precede complexity, but follows it.”</em><p>
<b>Dieter Rams:</b><br><em>“Less, but better.”</em></p>
<p>Now that you’ve done <em>it</em>, did you really understand <em>it</em>? Let’s check.</p>
<p>Can you do <em>it</em> better?
Can you now
write <em>it</em> in fewer lines and do you know how to make <em>it</em> run faster?
Can you see how <em>it</em> is same/different to other things?
And can you use those similarities to do more things with  <em>it</em>?
Finally, can you teach <em>it</em> quickly to newcomers?</p>
<p>E.g. do I understand a multi-objective semi-supervised explanation algorithms?
Well, Let’s check. </p>
<p>Here’s all that, most of which is coded in B(Ai)TTERY
that could be used for other learners.  </p>
<p>Also included here is literate programming,
self-documenting code and support for test-driven development.
All in around 500 lines of LUA: <br></p>
<p><code>awk &#39;!/^(--|[ \t]*$)/{n++}</code><br><code>END {print n&quot; lines&quot;}&#39; *.lua</code><br>=&gt; 500 lines</p>
<p>Share and enjoy.</p>
<h3 id="role-models">Role Models</h3>
<p>People that inspire me to code less, but better:<br>
<a href="https://www.youtube.com/watch?v=o9pEzgHorH0">Jack Diederich</a>, <a href="https://www.youtube.com/watch?v=l2btv0yUPNQ">Hilary Mason</a>,
<a href="https://brianmcfee.net/papers/ismir2011_sptree.pdf">Brian McFee</a>,<br><a href="https://www.oreilly.com/library/view/beautiful-code/9780596510046/ch01.html">Brian Kernighan</a>,
<a href="https://github.com/joelgrus/data-science-from-scratch">Joel Grus</a>.<p>
Especially the LISPers: <br>
(<a href="https://gigamonkeys.com/book/">Peter Seibel</a>
  (<a href="https://doc.lagout.org/programmation/Lisp/Land%20of%20Lisp_%20Learn%20to%20Program%20in%20Lisp%2C%20One%20Game%20at%20a%20Time%20%5BBarski%202010-11-15%5D.pdf">Conrad Barski</a>
  (<a href="http://www.paulgraham.com/onlisp.html">Paul Graham</a><br>
    (<a href="http://norvig.com/lispy.html">Peter Norvig</a>
      (<a href="https://dspace.mit.edu/bitstream/handle/1721.1/5790/AIM-353.pdf?sequence=2&amp;isAllowed=y">Guy Steele</a>))))).</p>

            </div>
            
        </li>
        
    </ul>
  </div>
</body>
</html>
